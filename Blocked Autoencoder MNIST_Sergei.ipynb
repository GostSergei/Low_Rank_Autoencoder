{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba1b037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f20f711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s.gostilovich/.venv/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d11486e",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0c24e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 1, 32, 32])\n",
      "tensor(1.)\n",
      "(tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]))\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Subset, Dataset, DataLoader\n",
    "\n",
    "train_ds_mnist = torchvision.datasets.MNIST('./files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                                 transforms.Resize(32),\n",
    "                                 torchvision.transforms.ToTensor(),\n",
    "                             ]))\n",
    "test_ds_mnist = torchvision.datasets.MNIST('./files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                                 transforms.Resize(32),\n",
    "                                 torchvision.transforms.ToTensor(),\n",
    "                             ]))\n",
    "\n",
    "# dataset and dataloader\n",
    "TRAIN_SIZE = 60000\n",
    "TEST_SIZE = 10000\n",
    "BATCH_SIZE = 32\n",
    "dl = DataLoader(train_ds_mnist, batch_size=BATCH_SIZE,     num_workers=10)\n",
    "dl_test = DataLoader(test_ds_mnist, batch_size=BATCH_SIZE, num_workers=10)\n",
    "\n",
    "#full dataset train\n",
    "FULL_TRAIN_SIZE = 60000\n",
    "dl_full = DataLoader(train_ds_mnist, batch_size=FULL_TRAIN_SIZE)\n",
    "for x, y in dl_full:\n",
    "    X_full_train = x\n",
    "    targets = y\n",
    "    break\n",
    "\n",
    "#full dataset train\n",
    "FULL_TEST_SIZE = 10000\n",
    "dl_full = DataLoader(test_ds_mnist, batch_size=FULL_TEST_SIZE)\n",
    "for x, y in dl_full:\n",
    "    X_full_test = x\n",
    "    targets_test = y\n",
    "    break\n",
    "\n",
    "print(X_full_train.shape)\n",
    "print(torch.max(X_full_train))\n",
    "print(targets.unique(return_counts=True))\n",
    "\n",
    "DS_IN_CHANNELS=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "247c1cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "torch.Size([50000, 3, 32, 32]) torch.Size([10000, 3, 32, 32])\n",
      "tensor(1.)\n",
      "(tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000]))\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Subset, Dataset, DataLoader\n",
    "\n",
    "train_ds_cifar10 = torchvision.datasets.CIFAR10('./files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                                 transforms.Resize(32),\n",
    "                                 torchvision.transforms.ToTensor(),\n",
    "                             ]))\n",
    "test_ds_cifar10  = torchvision.datasets.CIFAR10('./files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                                 transforms.Resize(32),\n",
    "                                 torchvision.transforms.ToTensor(),\n",
    "                             ]))\n",
    "\n",
    "# dataset and dataloader\n",
    "TRAIN_SIZE = 50000\n",
    "TEST_SIZE = 10000\n",
    "BATCH_SIZE = 32\n",
    "dl = DataLoader(train_ds_cifar10, batch_size=BATCH_SIZE,     num_workers=10)\n",
    "dl_test = DataLoader(test_ds_cifar10, batch_size=BATCH_SIZE, num_workers=10)\n",
    "\n",
    "#full dataset train\n",
    "FULL_TRAIN_SIZE = 50000\n",
    "dl_full = DataLoader(train_ds_cifar10, batch_size=FULL_TRAIN_SIZE)\n",
    "for x, y in dl_full:\n",
    "    X_full_train = x\n",
    "    targets = y\n",
    "    break\n",
    "\n",
    "#full dataset train\n",
    "FULL_TEST_SIZE = 10000\n",
    "dl_full = DataLoader(test_ds_cifar10, batch_size=FULL_TEST_SIZE)\n",
    "for x, y in dl_full:\n",
    "    X_full_test = x\n",
    "    targets_test = y\n",
    "    break\n",
    "\n",
    "print(X_full_train.shape, X_full_test.shape)\n",
    "print(torch.max(X_full_train))\n",
    "print(targets.unique(return_counts=True))\n",
    "\n",
    "DS_IN_CHANNELS=3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb83e4a",
   "metadata": {},
   "source": [
    "# Upload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d7e2feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:1' #torch.device(torch.cuda.get_device_name(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90bd7662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_TYPE = 'LRAE'\n",
    "MODEL_TYPE = 'AE'\n",
    "\n",
    "# Upload the model\n",
    "model_dir = 'evaluation'\n",
    "# model_dir = 'test_1_save'\n",
    "# model_dir = ''\n",
    "\n",
    "# model_name = 'MNIST__VAE_128__50__10ktrain'\n",
    "model_name = 'test1__MNIST__AE__128__0.01'\n",
    "# model_name = 'test1__MNIST__LRAE__128__0.01__10'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "GOOD_MODEL_TYPE = ['VAE', 'AE', 'LRAE']\n",
    "assert MODEL_TYPE in GOOD_MODEL_TYPE, f\"Error, bad model type, select from: {GOOD_MODEL_TYPE}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6921d527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.R1AE import ConvLRAE, ConvVAE, ConvAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9ad21fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "IN_FEATURES = 256*2*2\n",
    "OUT_FEATURES = 128\n",
    "N_BINS = 20\n",
    "GRID = torch.arange(1,N_BINS+1).to(device)/N_BINS\n",
    "\n",
    "# nonlinearity = \n",
    "\n",
    "DROPOUT = 0.0\n",
    "TEMP = 0.5\n",
    "SAMPLING = 'gumbell'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c428a11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE was inisialized\n"
     ]
    }
   ],
   "source": [
    "if MODEL_TYPE == 'LRAE':\n",
    "     model = ConvLRAE(IN_FEATURES, OUT_FEATURES, N_BINS, GRID, dropout=DROPOUT, nonlinearity=nn.ReLU(),\n",
    "                sampling=SAMPLING, temperature=TEMP, in_channels=DS_IN_CHANNELS).to(device)\n",
    "elif MODEL_TYPE == 'VAE':\n",
    "    model = ConvVAE(IN_FEATURES, OUT_FEATURES, nonlinearity=nn.ReLU(), in_channels=DS_IN_CHANNELS).to(device)\n",
    "elif MODEL_TYPE == 'AE':\n",
    "    model = ConvAE(IN_FEATURES, OUT_FEATURES, nonlinearity=nn.ReLU(), in_channels=DS_IN_CHANNELS).to(device)\n",
    "else:\n",
    "    assert False, f\"Error, bad model type, select from: {GOOD_MODEL_TYPE}\"\n",
    "    \n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    \n",
    "print(f\"{MODEL_TYPE} was inisialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3ffa481d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 32, 32]) --> torch.Size([2, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "X_in = torch.rand(X_full_test.shape)[:2].to(device)\n",
    "X_out = model(X_in)\n",
    "print(f\"{X_in.shape} --> {X_out.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c034ec9",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360370ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "51b68373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup training\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "# PATH = PATH\n",
    "EPOCHS = 50\n",
    "ALPHA = 0.01\n",
    "\n",
    "loss_list_train = []\n",
    "loss_train_cum = 0\n",
    "\n",
    "loss_list_test = []\n",
    "loss_test_cum = 0\n",
    "i = 0\n",
    "loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb03a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "03d2f1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/s.gostilovich/Low_rank AE/Low_Rank_Autoencoder/Blocked Autoencoder MNIST_Sergei.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfedor/home/s.gostilovich/Low_rank%20AE/Low_Rank_Autoencoder/Blocked%20Autoencoder%20MNIST_Sergei.ipynb#Y222sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(EPOCHS)):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfedor/home/s.gostilovich/Low_rank%20AE/Low_Rank_Autoencoder/Blocked%20Autoencoder%20MNIST_Sergei.ipynb#Y222sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39m# Forward pass: Compute predicted y by passing x to the model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfedor/home/s.gostilovich/Low_rank%20AE/Low_Rank_Autoencoder/Blocked%20Autoencoder%20MNIST_Sergei.ipynb#Y222sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m         \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfedor/home/s.gostilovich/Low_rank%20AE/Low_Rank_Autoencoder/Blocked%20Autoencoder%20MNIST_Sergei.ipynb#Y222sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39m# Training\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfedor/home/s.gostilovich/Low_rank%20AE/Low_Rank_Autoencoder/Blocked%20Autoencoder%20MNIST_Sergei.ipynb#Y222sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     model\u001b[39m.\u001b[39mtrain() \u001b[39m# Model to train\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bfedor/home/s.gostilovich/Low_rank%20AE/Low_Rank_Autoencoder/Blocked%20Autoencoder%20MNIST_Sergei.ipynb#Y222sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mfor\u001b[39;00m x_batch, y_batch \u001b[39min\u001b[39;00m dl:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfedor/home/s.gostilovich/Low_rank%20AE/Low_Rank_Autoencoder/Blocked%20Autoencoder%20MNIST_Sergei.ipynb#Y222sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m         x_batch, y_batch \u001b[39m=\u001b[39m x_batch\u001b[39m.\u001b[39mto(device), y_batch\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfedor/home/s.gostilovich/Low_rank%20AE/Low_Rank_Autoencoder/Blocked%20Autoencoder%20MNIST_Sergei.ipynb#Y222sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m         \u001b[39m# model forward\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfedor/home/s.gostilovich/Low_rank%20AE/Low_Rank_Autoencoder/Blocked%20Autoencoder%20MNIST_Sergei.ipynb#Y222sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m         \u001b[39m# 2d downsampling\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch/utils/data/dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1315\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1316\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1317\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1319\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch/utils/data/dataloader.py:1282\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1282\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1283\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1284\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch/utils/data/dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1108\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1120\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1121\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1122\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1123\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib64/python3.9/multiprocessing/queues.py:122\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rlock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    121\u001b[0m \u001b[39m# unserialize the data after having released the lock\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[39mreturn\u001b[39;00m _ForkingPickler\u001b[39m.\u001b[39;49mloads(res)\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch/multiprocessing/reductions.py:311\u001b[0m, in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[39mreturn\u001b[39;00m storage\n\u001b[1;32m    310\u001b[0m     storage \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_new_shared_fd_cpu(fd, size)\n\u001b[0;32m--> 311\u001b[0m     shared_cache[fd_id(fd)] \u001b[39m=\u001b[39m StorageWeakRef(storage)\n\u001b[1;32m    312\u001b[0m     \u001b[39mreturn\u001b[39;00m storage\n\u001b[1;32m    313\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch/multiprocessing/reductions.py:29\u001b[0m, in \u001b[0;36mStorageWeakRef.__init__\u001b[0;34m(self, storage)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, storage):\n\u001b[0;32m---> 29\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcdata \u001b[39m=\u001b[39m storage\u001b[39m.\u001b[39;49m_weak_ref()\n\u001b[1;32m     30\u001b[0m     \u001b[39m# Save a direct reference to _free_weak_ref because the `torch` module\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[39m# might be cleared during Python shutdown before this module is cleared.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_free_weak_ref \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mStorage\u001b[39m.\u001b[39m_free_weak_ref\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "######## Training\n",
    "print(\"Training of the model\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "alpha_kl = ALPHA\n",
    "alpha_entropy = ALPHA\n",
    "if MODEL_TYPE == 'LRAE':\n",
    "    alpha_entropy *= OUT_FEATURES/8\n",
    "    print(f\"Alpha update = {OUT_FEATURES/8: .3f}\")\n",
    "    print(f\"Entropy alpha = {alpha_entropy: .3e}\")\n",
    "\n",
    "\n",
    "# epoch_save_backup = EPOCH_SAVE_BACKUP\n",
    "# show_loss_backup = SHOW_LOSS_BACKUP\n",
    "\n",
    "\n",
    "# Training\n",
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "        \n",
    "    # Training\n",
    "    model.train() # Model to train\n",
    "    for x_batch, y_batch in dl:\n",
    "\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        # model forward\n",
    "        # 2d downsampling\n",
    "        x_down = model.down(x_batch)\n",
    "        B, C, H, W = x_down.shape\n",
    "        x_flat = x_down.view(B,C*H*W)\n",
    "        \n",
    "        encoded_out_dim, factors_probability = model.low_rank.low_rank_pants(x_flat)\n",
    "        decoded_1d = model.low_rank.decoder(encoded_out_dim)\n",
    "        \n",
    "        # 2d upsampling\n",
    "        decoded_2d_small = decoded_1d.view(B, C, H, W)\n",
    "        decoded_2d = model.up(decoded_2d_small)\n",
    "        \n",
    "        # loss\n",
    "\n",
    "#         loss_entropy = torch.sum(torch.log(factors_probability+1e-9)*factors_probability,dim=-1)\n",
    "        # factors_probability = nn.Softmax(dim=-1)(factors_probability)\n",
    "        # loss_entropy = torch.sum(torch.log(factors_probability+1e-9)*factors_probability,dim=-1)\n",
    "        loss = criterion(decoded_2d.view(-1), x_batch.view(-1)) \n",
    "        if MODEL_TYPE == 'VAE':\n",
    "            loss += alpha_kl*factors_probability.mean()  # KL loss\n",
    "            \n",
    "        if MODEL_TYPE == 'LRAE':\n",
    "            factors_probability = nn.Softmax(dim=-1)(factors_probability)\n",
    "            loss_entropy = torch.sum(torch.log(factors_probability+1e-9)*factors_probability,dim=-1)            \n",
    "            loss += alpha_entropy*torch.mean(torch.exp(loss_entropy)) # entropy loss\n",
    "            \n",
    "            \n",
    "          \n",
    "            \n",
    "            \n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # accumulate loss\n",
    "        loss_train_cum += loss.item()\n",
    "        \n",
    "        # validation and saving\n",
    "        i += 1\n",
    "        if i % 100 == 0:\n",
    "            loss_list_train.append(loss_train_cum/100)\n",
    "            loss_train_cum = 0\n",
    "            with torch.no_grad():\n",
    "                model.eval() # put to eval\n",
    "                for x_batch, y_batch in dl_test:\n",
    "                    # model forward\n",
    "                    x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                    x_decoded = model(x_batch)\n",
    "\n",
    "                    loss_test = criterion(x_decoded.view(-1), x_batch.view(-1))\n",
    "                    loss_test_cum += loss_test.item()\n",
    "                    \n",
    "            assert torch.isnan(x_decoded).sum() == 0, f\"Error! Nan values ({torch.isnan(x_decoded).sum()}) in models output\"\n",
    "      \n",
    "            # save to list\n",
    "            loss_list_test.append(loss_test_cum/len(dl_test))\n",
    "            loss_test_cum = 0\n",
    "          \n",
    "            \n",
    "    # # backup saving  \n",
    "    # if epoch%epoch_save_backup == 0:\n",
    "    #     torch.save({\n",
    "    #         'epoch': epoch,\n",
    "    #         'model_state_dict': model.state_dict(),\n",
    "    #         'optimizer_state_dict': optimizer.state_dict(),\n",
    "    #         'loss': loss,\n",
    "    #         'loss_list_train': loss_list_train,\n",
    "    #         'loss_list_test': loss_list_test,\n",
    "            \n",
    "    #         }, PATH + f\"__{epoch}.pth\")\n",
    "      \n",
    "    # # loss printing        \n",
    "    # if (epoch % show_loss_backup == show_loss_backup-1) or (epoch == EPOCHS -1):\n",
    "    #     fig = plt.figure(figsize=(6,3))\n",
    "    #     plt.plot(loss_list_train, alpha=0.5, label='train')\n",
    "    #     plt.plot(loss_list_test, alpha=0.5, label='test')\n",
    "    #     plt.legend()\n",
    "    #     plt.savefig( PATH  + \"_loss.png\")\n",
    "    #     pass\n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "# print(\"Finishing of the training...\")\n",
    "# torch.save({\n",
    "#         'epoch': epoch,\n",
    "#         'model_state_dict': model.state_dict(),\n",
    "#         'optimizer_state_dict': optimizer.state_dict(),\n",
    "#         'loss': loss,\n",
    "#         'loss_list_train': loss_list_train,\n",
    "#         'loss_list_test': loss_list_test,\n",
    "        \n",
    "#         }, PATH + f\"__{epoch}__end.pth\")\n",
    "\n",
    "# print(\"Model training was successfully finished and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35934696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b708977c",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2860efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Upload the model\n",
    "# model_name = 'test1__MNIST__LRAE__128__0.01__5'\n",
    "# model_dir = 'test_1_save'\n",
    "model_path = os.path.join(model_dir, model_name + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911416c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading\n",
    "# PATH = \"MNIST__gumbell__entropy__200\"\n",
    "# PATH = \"MNIST__VAE__8__25\"\n",
    "PATH = model_path\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "loss_list_train = checkpoint['loss_list_train']\n",
    "loss_list_test = checkpoint['loss_list_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b561b0",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5010e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.evaluation import inf_by_layers, check_reconstruction, gen_idx_for_batches, display_datasets\n",
    "from models.evaluation import gen_gm_dataset, update_FID_class, ManualFID, prepare_to_FID\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance as tm_FrechetInceptionDistance\n",
    "from torcheval.metrics import FrechetInceptionDistance\n",
    "\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
